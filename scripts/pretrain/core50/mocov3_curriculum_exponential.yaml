defaults:
  - _self_
  - augmentations: asymmetric.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "mocov3-curriculum-mae-exponential-core50-bs3x64-rev"
method: "curriculum_mocov3"  # Use our new curriculum method
backbone:
  name: "resnet18"
method_kwargs:
  proj_hidden_dim: 4096
  proj_output_dim: 256
  pred_hidden_dim: 4096
  temperature: 0.1
  
  # Curriculum learning parameters
  curriculum_type: "mae"
  curriculum_reverse: True
  curriculum_strategy: "exponential"  # Use exponential weighting
  curriculum_warmup_epochs: 10
  curriculum_weight: 1.0
  reconstruction_masking_ratio: 0.75
  
momentum:
  base_tau: 0.996
  final_tau: 0.996
data:
  dataset: temporal_core50  # Use our temporal dataset
  train_path: "/home/brothen/core50_arr.h5"  # Path to your H5 file
  val_path: "/home/brothen/core50_arr.h5"
  format: "h5"
  num_workers: 4
  dataset_kwargs:
    # Use standard Core50 train sessions
    backgrounds: ["s1", "s2", "s4", "s5", "s6", "s8", "s9", "s11"]
    val_backgrounds: ["s3", "s7", "s10"]  # Validation sessions
    time_window: 15  # Temporal offset window
optimizer:
  name: "lars"
  batch_size: 64
  lr: 1.6
  classifier_lr: 3e-3
  weight_decay: 1e-6
  no_labels: False  # Core50 has labels
scheduler:
  name: "warmup_cosine"
  warmup_epochs: 0.01          
checkpoint:
  enabled: True
  dir: "trained_models"
  frequency: 10
  keep_prev: True
  every_n_iter: 0
auto_resume:
  enabled: False
knn_clb:
  enabled: True  # Set to True if you want to use KNN evaluation during training
  dataset: "core50"  # Required even if disabled
  train_path: "/home/brothen/core50_arr.h5"
  val_path: "/home/brothen/core50_arr.h5"
  num_workers: 4
  batch_size: 64
  k: [10, 20, 50, 100]
  temperature: 0.07
  train_backgrounds: ["s1", "s2", "s4", "s5", "s6", "s8", "s9", "s11"]
  val_backgrounds: ["s3", "s7", "s10"]
# overwrite PL stuff
max_epochs: 100
devices: [0,1,2]  # Adjust based on available GPUs
sync_batchnorm: True
accelerator: "gpu"
strategy: "ddp"
precision: 32
# Validation settings
num_sanity_val_steps: 2