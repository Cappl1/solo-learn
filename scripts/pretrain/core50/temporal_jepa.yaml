# Config for Temporal I-JEPA pretraining on CORe50 dataset with ResNet-18 backbone
# Compatible with main_pretrain.py

defaults:
  - _self_
  - augmentations: asymmetric.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "temporal_jepa-core50-resnet18"
method: "temporal_jepa"
no_validation: False

backbone:
  name: "resnet18"
    
method_kwargs:
  proj_output_dim: 256
  proj_hidden_dim: 2048
  delta_max: 15
  temperature: 1.0
  var_lambda: 1.0
  cov_lambda: 1.0

momentum:
  base_tau: 0.996
  final_tau: 0.996

# NOTE: For Temporal JEPA we need at least 2 views (current frame and future frame)
# We're using the standard data pipeline but treating the first two views as temporal pairs
data:
  dataset: "temporal_core50"
  train_path: "/home/brothen/core50_arr.h5"
  val_path: "/home/brothen/core50_arr.h5"
  format: "h5"
  num_classes: 50
  fraction: -1.0
  num_workers: 4
  num_large_crops: 2  # We need exactly 2 crops for temporal prediction
  num_small_crops: 0
  dataset_kwargs:
    backgrounds: ["s1", "s2", "s4", "s5", "s6", "s8", "s9", "s11"]
    val_backgrounds: ["s3", "s7", "s10"]
    time_window: 15

optimizer:
  name: "lars"
  batch_size: 64
  lr: 0.3  # Lower learning rate for stability
  classifier_lr: 3e-3
  weight_decay: 1e-6
  no_labels: False

scheduler:
  name: "warmup_cosine"
  warmup_epochs: 0.01
  warmup_start_lr: 0.0

checkpoint:
  enabled: True
  dir: "trained_models"
  frequency: 1
  keep_prev: True
  every_n_iter: 5000

auto_resume:
  enabled: False

# KNN evaluation callback config
knn_clb:
  enabled: False # Disable for simplicity while getting things working
  dataset: "core50"
  train_path: "/home/brothen/core50_arr.h5"
  val_path: "/home/brothen/core50_arr.h5"
  num_workers: 4
  batch_size: 64
  k: [10, 20, 50, 100]
  temperature: 0.07
  train_backgrounds: ["s1", "s2", "s4", "s5", "s6", "s8", "s9", "s11"]
  val_backgrounds: ["s3", "s7", "s10"]

# Logging settings
console_logger: True

# training settings
max_epochs: 100
devices: [0,1,2]
sync_batchnorm: True
accelerator: "gpu"
strategy: "ddp_find_unused_parameters_true"
precision: 32
num_sanity_val_steps: 2
check_val_every_n_epoch: 1
limit_val_batches: 1.0
limit_train_batches: 1.0
log_every_n_steps: 10
num_nodes: 1

# difficulty metrics callback configuration
difficulty_metrics:
  enabled: True
  dataset_path: "/home/brothen/core50_arr.h5"
  eval_frequency: 1
  num_samples: 10000
  compute_rank_stability: True
  save_metrics: True
  output_dir: "/home/brothen/solo-learn/difficulty_metrics_output/jepa3_10k"
  dataset_kwargs:
    backgrounds: ["s1", "s2", "s4", "s5", "s6", "s8", "s9", "s11"]
    time_window: 15
  model_type: "jepa" 