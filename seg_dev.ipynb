{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:27:56.591564Z",
     "start_time": "2024-12-31T11:27:55.266844Z"
    }
   },
   "cell_type": "code",
   "source": "import torchvision.transforms.v2 as T",
   "id": "ae775098ef602054",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:27:56.621638Z",
     "start_time": "2024-12-31T11:27:56.617881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.tv_tensors import Mask\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torchvision.datasets import wrap_dataset_for_transforms_v2\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "id": "bc921d37442a1726",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:27:56.635725Z",
     "start_time": "2024-12-31T11:27:56.630965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ],
   "id": "483120a67fb0d399",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:27:57.789149Z",
     "start_time": "2024-12-31T11:27:57.786539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def f(x):\n",
    "    print(type(x))\n",
    "    x = x.clone()  # Ensure no in-place modifications\n",
    "    x[x == 255] = 0\n",
    "    return x\n",
    "\n",
    "\n",
    "l = T.Lambda(f, Mask)"
   ],
   "id": "586667f047f909a4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:27:58.252220Z",
     "start_time": "2024-12-31T11:27:58.249321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = T.Compose([\n",
    "    T.ToImage(),\n",
    "    l,\n",
    "    T.RandomResizedCrop(size=(224, 224), antialias=True, scale=(0.5, 1.0)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ],
   "id": "18d72f49a548b0c1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:28:07.517421Z",
     "start_time": "2024-12-31T11:27:58.722742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = VOCSegmentation(root=\"/Users/ts/Datasets/\", year=\"2012\", image_set=\"train\", download=True, transforms=transform)\n",
    "ds = wrap_dataset_for_transforms_v2(ds)\n",
    "\n",
    "len(ds)"
   ],
   "id": "173dda89aa1ae02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/ts/Datasets/VOCtrainval_11-May-2012.tar\n",
      "Extracting /Users/ts/Datasets/VOCtrainval_11-May-2012.tar to /Users/ts/Datasets/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:28:07.543370Z",
     "start_time": "2024-12-31T11:28:07.525622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img, mask = ds[0]\n",
    "img.shape, mask.unique()"
   ],
   "id": "24e59351d55df267",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.tv_tensors._mask.Mask'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), tensor([ 0,  1, 15], dtype=torch.uint8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:13:49.193433Z",
     "start_time": "2024-12-31T11:13:49.178366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img, mask = transform(img, mask)\n",
    "img.shape, mask.shape"
   ],
   "id": "dfe33a447174d286",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), torch.Size([1, 224, 224]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:05:39.607941Z",
     "start_time": "2024-12-31T11:05:39.605862Z"
    }
   },
   "cell_type": "code",
   "source": "dl = DataLoader(ds, batch_size=2, shuffle=False, num_workers=2)",
   "id": "293c86e84bba0440",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T11:05:42.288281Z",
     "start_time": "2024-12-31T11:05:39.630823Z"
    }
   },
   "cell_type": "code",
   "source": "next(iter(dl))",
   "id": "37d0003aace72a84",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 316, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 173, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 173, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 145, in collate\n    return collate_fn_map[collate_type](batch, collate_fn_map=collate_fn_map)\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 213, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torchvision/tv_tensors/_tv_tensor.py\", line 77, in __torch_function__\n    output = func(*args, **kwargs or dict())\nRuntimeError: stack expects each tensor to be equal size, but got [1, 281, 500] at entry 0 and [1, 375, 500] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdl\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1344\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1345\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[0;32m-> 1346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[1;32m   1371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[0;32m-> 1372\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/_utils.py:705\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    701\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    702\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 705\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 316, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 173, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 173, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 145, in collate\n    return collate_fn_map[collate_type](batch, collate_fn_map=collate_fn_map)\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 213, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n  File \"/Users/ts/miniconda3/envs/new_ml/lib/python3.9/site-packages/torchvision/tv_tensors/_tv_tensor.py\", line 77, in __torch_function__\n    output = func(*args, **kwargs or dict())\nRuntimeError: stack expects each tensor to be equal size, but got [1, 281, 500] at entry 0 and [1, 375, 500] at entry 1\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T11:01:56.386676Z",
     "start_time": "2024-12-30T11:01:56.373183Z"
    }
   },
   "cell_type": "code",
   "source": "out = torch.randn(8, 197, 768)",
   "id": "2d8832237d067771",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T11:05:46.615346Z",
     "start_time": "2024-12-30T11:05:46.611933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SegmentationHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 width: int,\n",
    "                 height: int,\n",
    "                 num_classes: int,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.classifier = nn.Conv2d(in_channels, num_classes, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.reshape(-1, self.height, self.width, self.in_channels) # (bs, num_tokens, c) -> (bs, h, w, c)\n",
    "        x = x.permute(0, 3, 1, 2) # (bs, h, w, c) -> (bs, c, h, w)\n",
    "        return self.classifier(x) # (bs, c, h, w) -> (bs, num_classes, h, w)\n",
    "\n",
    "head = SegmentationHead(in_channels=768, width=14, height=14, num_classes=2)"
   ],
   "id": "490caad28608f4fd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T11:06:27.567262Z",
     "start_time": "2024-12-30T11:06:27.562605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits = head(out[:, 1:, :])\n",
    "logits.shape"
   ],
   "id": "abae8ad4425887a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 14, 14])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T11:08:10.098359Z",
     "start_time": "2024-12-30T11:08:10.093305Z"
    }
   },
   "cell_type": "code",
   "source": "logits = F.interpolate(logits, size=(224, 224), mode=\"bilinear\", align_corners=False)",
   "id": "abb190e7e514c4a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T11:09:00.843458Z",
     "start_time": "2024-12-30T11:09:00.839961Z"
    }
   },
   "cell_type": "code",
   "source": "logits.squeeze().shape",
   "id": "c46c81dfdebee580",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "953bcaf33c15b29f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
